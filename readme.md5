1. Написать про отличия между версиями MobileNet (добавить ссылки на статьи);
        
        MobileNet_V1 [https://arxiv.org/pdf/1704.04861.pdf]
        Основная идея связана с заменой стандартных сверточных слоев deepwise separable convolution(DWC) слоями, 
    которые позволяют сильно сократить вычислительные затраты(почти в размер_ядра_свертки**2) благодаря использованию 
    принципа последовательного использования глубинно-разделенной свертки(DWC) с последующими слоями с батч-нормализацией 
    и функцией активации(ReLU) и стандартной свертки с батч-нормализацией и функцией активации(ReLU) - (pointwise 
    convolution - PWC) для генерации линейных комбинаций выхода дипвайс слоя и новых признаков(фичей). 
        DWC применяет одноканальный фильтр для свертки с исходными данными, когда стандартная свертка применяет 
    фильтр с числом каналов, равным числу каналов в исходных данных.  
    №========================================================================================================================== 
        MobileNet_V2 [https://arxiv.org/pdf/1801.04381.pdf]
    Модернизация предыдущей модели(MobileNet_V1): основная идея связана с добавлением BottleNeck 
    (опционально с соединениями для быстрого доступа(shortcut connections - аналогично ResNet - методика обучения по остаточному 
    принципу)) и заменой функции активации на ReLU6. сам DWC слой также немного притерпел изменения: теперь структура выглядит 
    следующим образом:
    1. PWC для искусственного увеличения числа каналов(+ BatchNorm, ReLU6)
    
    2. DWC(принимает данные с искусственно увеличенным числом каналов, уменьшает пространственные параметры 
    из-за увеличенного шага(stride = 2))
    
    3. PWC для занижения числа выходных каналов (+ BatchNorm, без функции активации)
    
    4. при одинаковых значениях входных и выходных каналов и stride == 1 используется shortcut connections.
        
        shortcut connections(соединения для быстрого доступа)[https://neurohive.io/ru/vidy-nejrosetej/resnet-34-50-101/]
    Впервые ввели Microsoft для преодоления проблемной ситуации, когда более глубокая сеть начинает сворачиваться, 
    возникает проблема: с увеличением глубины сети точность сначала увеличивается, а затем быстро ухудшается. Снижение 
    точности обучения показывает, что не все сети легко оптимизировать. Вместо того, чтобы надеяться на то, что каждые 
    несколько stacked layers непосредственно соответствуют желаемому основному представлению, они явно позволяют этим 
    слоям соответствовать «остаточному». Формулировка F(x) + x может быть реализована с помощью нейронных сетей с соединениями 
    для быстрого доступа - или же говоря проще: такой трюк позволяет избежать случая  затухания(зануления) градиентов.
    Соединения быстрого доступа пропускают один или несколько слоев и выполняют сопоставление идентификаторов. Их выходы 
    добавляются к выходам stacked layers. При использовании такой техники можно решить множество проблем, таких как:
    
    - относительная простота оптимизации: «простые» сети (которые просто складывают слои) показывают большую ошибку 
    обучения, когда глубина увеличивается.
    - можно точность благодаря увеличению глубины.
    №==========================================================================================================================
        MobileNet_V3 [https://arxiv.org/pdf/1905.02244.pdf]
    Модернизация предыдущей модели(MobileNet_V2):  
    1. Заменены функции активаций - ReLU на Hard-Swish(x * torch.nn.functional.relu6(x+3, self.inplace) / 6)
    
    2. Добавлен SE(Squeeze-Excitation Block [https://arxiv.org/pdf/1709.01507.pdf] 
        - так называемый механизм аттеншна), который 
        позволяет параметризировать каждый из каналов ядер сверток, что полезно для самой сети при регулировании весов. 
        В самом SE блоке после 2го полносвязного слоя функция активации заменена на пользовательскую (HardSigmoid
        (torch.nn.functional.relu6(x+3, self.inplace) / 6))
    
    3. Введены параметры для донастройки сети по глубине и пространственным параметрам - есть возможность регулирования
        пропускной способности модели и точности (tradeof между качеством и скоростью)
        
    4. Архитектура сети (функциональные параметры такие как: кол-во блоков, параметры блоков(страйд, размер ядра свертки 
        итд))  подбирались в автоматизированнном режиме при помощи модели обучения с подкреплением. Интересно, что 
        некоторые блоки используют ядрра сверток размером 5х5: можно было б заменить каскадом сверток 3х3 для еще большей
        оптимизации по вычислительным затратам.
-------------------------------------------------------------------------------------------------------------------------------
2. Предоставить инструкцию по запуску обучения модели;
    Основные параметры для запуска обучения сети уже заложил в парсер по дефолту, все согласно данным из статьи по последней
    версии сети.
    Структура следующая:
    # DataSet params:
    parser.add_argument('--dataset_path',  default='dataset', type=str,   help='dataset name') 
    parser.add_argument('--dataset_split', default='train',   type=str,   help='train or test') 
    parser.add_argument('--batch_size',    default=450,       type=int,   help='150 for single RTX 2080 TI') 
    # Net:
    parser.add_argument('--net_version',   default='v3',      type=str,   help='network version') 
    # Optimizer params: 
    parser.add_argument('--optimizer_kind',default='RMSprop', type=str,   help='optimizer type') 
    parser.add_argument('--lr',            default=0.1,       type=float, help='learning rate') 
    parser.add_argument('--momentum',      default=0.9,       type=float, help='momentum') 
    parser.add_argument('--weight_decay',  default=1e-5,      type=float, help='weight_decay') 
    parser.add_argument('--step_size',     default=3,         type=int,   help='step_size') 
    # Functional HW params:
    parser.add_argument('--num_gpus',      default=3,         type=int,   help='num_gpus') 
    parser.add_argument('--num_epoch',     default=300,       type=int,   help='num_epoch') 
-------------------------------------------------------------------------------------------------------------------------------
3. Предоставить инструкцию по запуску тестового скрипта;
    Основные параметры для запуска обучения сети уже заложил в парсер по дефолту. Необходимо лишь дописать путь к чекпойнту: python3 test.py --checkpoint './YYYY_MM_DD_HH_MM/MobileNet{args.net_version}_{args.optimizer_kind}_{num_of_current_epoch}_{epoch_avg_loss}.pth'
--------------------------------------------------------------------------------------------------------------------------------
4. Описать возможные улучшения созданного решения;
    В числе возможных улучшений вижу: 
    - добавление апсемплинга и соединений быстрого доступа на тех слоях, где их нет
    - считаю, есть смысл попробовать увеличить входной размер изображения с 224 , к примеру до 416(для YOLO3 такой трюк 
        сработал)
    - попытка разбавить DWC блоки deformable свертками. 
-------------------------------------------------------------------------------------------------------------------------------
5. (Опциально) Описать проблемы с которыми пришлось столкнуться при решении данного задания;
    - замешкался при написании загрузчика данных - давно не практиковался :)
    - хотел написать функцию потерь, но не рассчитал времени, поэтому использую встроенную.
-------------------------------------------------------------------------------------------------------------------------------Технические требования

    При сдаче задания без Docker следует:
        предоставить readme.txt (описание в п.5);
        предоставить файл requirements.txt со всеми зависимостями необходимыми для запуска обучения и тестирования: 
        мы установим чистый virtual env и поставим всё туда;
        
    При сдаче задания с Docker следует (опционально — будет плюсом):
        предоставить readme.txt (описание в п.5);
        предоставить Dockerfile, собирающий образ;  
        предоставить скрипт, запускающий контейнер; 
        
        TRAIN
        Для запуска сборки контейнера использовать следующую команду docker build . -f Dockerfile_train -t mobilenet_v3_train
        Для запуска контейнера использовать команду NV_GPU=0 nvidia-docker run --shm-size 8G -it mobilenet_v3_train
        
        Перед запуском теста подправить значение для используемого чекпойнта в файле test.sh (по умолчанию стоит - "")
        TEST
        Для запуска сборки контейнера использовать следующую команду docker build . -f Dockerfile_test -t mobilenet_v3_test
        Для запуска контейнера использовать команду NV_GPU=0 nvidia-docker run --shm-size 8G -it mobilenet_v3_train

        NV_GPU может принимать номера карт, подключенных к конкретному кластеру. Если используется несколько карт - имеет смысл также 
        указать их количество в файле test.sh (по умолчанию стоит - 1)
